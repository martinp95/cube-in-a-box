{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184c9541",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will extract training data from the ODC using geometries within a geojson. The dataset will use the NNI level labels within the 'data/nni_training_spain.geojson' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82235194",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbandindices\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_indices\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatahandling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mostcommon_crs\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_training_data\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     20\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/machine_learning/../tools/classification.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask_ml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelPostFit\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geometry\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assign_crs\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask_ml'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import geopandas as gpd\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from tools.plotting import map_shapefile\n",
    "from tools.bandindices import calculate_indices\n",
    "from tools.datahandling import mostcommon_crs\n",
    "from tools.classification import collect_training_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the datacube\n",
    "dc = datacube.Datacube(app='Sentinel-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bc4a9",
   "metadata": {},
   "source": [
    "## Analisis parameters\n",
    "* path : The path to the input vector file from witch we wil extract training data.\n",
    "* field : This is the name of the columns in your shapefile attribute table that contains the class lables. The class lables must be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/nni_training_spain.geojson' \n",
    "field = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0561a",
   "metadata": {},
   "source": [
    "# Find the number of CPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ncpus = round(get_cpu_quota()) we can use this to find the number of cpu we have, we are going to set it to 2\n",
    "ncpus = 2;\n",
    "print('ncpus = ' + str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809a34e",
   "metadata": {},
   "source": [
    "# Preview input data\n",
    "We can load and preview our input data shapefile using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020710b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data shapefile\n",
    "input_data = gpd.read_file(path)\n",
    "\n",
    "# Plot first five rows\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f86357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training data in an interactive map\n",
    "map_shapefile(input_data, attribute=field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efe125",
   "metadata": {},
   "source": [
    "# Extracting training data\n",
    "The function collect_training_data takes our geojson containing class labels and extracts training data (features) from the datacube over the locations specified by the input geometries. The function will also pre-process our training data by stacking the arrays into a useful format and removing any NaN or inf values.The below variables can be set within the collect_training_data function:\n",
    "\n",
    "* zonal_stats: An optional string giving the names of zonal statistics to calculate across each polygon (if the geometries in the vector file are polygons and not points). Default is None (all pixel values are returned). Supported values are 'mean', 'median', 'max', and 'min'.\n",
    "\n",
    "In addition to the zonal_stats parameter, we also need to set up a datacube query dictionary for the Open Data Cube query such as measurements (the bands to load from the satellite), the resolution (the cell size), and the output_crs (the output projection). These options will be added to a query dictionary that will be passed into collect_training_data using the parameter collect_training_data(dc_query=query, ...). The query dictionary will be the only argument in the feature layer function which we will define and describe in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "zonal_stats = 'mean'\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'time': ('2022'),\n",
    "    'resolution': (-30, 30),\n",
    "    'measurements': ['red', 'green', 'blue', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
    "}\n",
    "\n",
    "# Identify the most common projection system in the input query\n",
    "output_crs = mostcommon_crs(dc=dc, product='s2_l2a', query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a208868",
   "metadata": {},
   "source": [
    "## Defining feature layers\n",
    "To create the desired feature layers, we pass instructions to collect_training_data through the feature_func parameter.\n",
    "\n",
    "feature_func: A function for generating feature layers that is applied to the data within the bounds of the input geometry. The feature_func must accept a dc_query dictionary, and return a single xarray.Dataset or xarray.DataArray containing 2D coordinates (i.e x, y - no time dimension). e.g.\n",
    "\n",
    "    def feature_function(query):\n",
    "        dc = datacube.Datacube(app='feature_layers')\n",
    "        ds = dc.load(**query)\n",
    "        ds = ds.mean('time')\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46615272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_layers(dc, query):\n",
    "    #load s2 annual geomedian\n",
    "    ds = dc.load(product='gm_s2_annual',\n",
    "                 **query)\n",
    "    \n",
    "    #calculate some band indices\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI'],\n",
    "                           drop=True,\n",
    "                           satellite_mission='s2')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dfcd0",
   "metadata": {},
   "source": [
    "Run the collect_training_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a747e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names, model_input = collect_training_data(\n",
    "                                    gdf=input_data,\n",
    "                                    dc_query=query,\n",
    "                                    ncpus=ncpus,\n",
    "                                    field=field,\n",
    "                                    zonal_stats=zonal_stats,\n",
    "                                    feature_func=feature_layers\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_names)\n",
    "print('')\n",
    "print(np.array_str(model_input, precision=2, suppress_small=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

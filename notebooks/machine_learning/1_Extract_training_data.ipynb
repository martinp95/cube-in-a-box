{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184c9541",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will extract training data from the ODC using geometries within a geojson. The dataset will use the NNI level labels within the 'data/nni_training_spain.geojson' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82235194",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn import model_selection\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from tools.plotting import map_shapefile\n",
    "from tools.bandindices import calculate_indices\n",
    "from tools.datahandling import mostcommon_crs\n",
    "from tools.classification import collect_training_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d6c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the datacube\n",
    "dc = datacube.Datacube(app='Sentinel-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bc4a9",
   "metadata": {},
   "source": [
    "## Analisis parameters\n",
    "* path : The path to the input vector file from witch we wil extract training data.\n",
    "* field : This is the name of the columns in your shapefile attribute table that contains the class lables. The class lables must be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c70390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/nni_training_egypt.geojson' \n",
    "field = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d29d8c",
   "metadata": {},
   "source": [
    "## Find the number of CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae3a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 1\n"
     ]
    }
   ],
   "source": [
    "#ncpus=round(get_cpu_quota()) Calculate the number of cpus we set it to 1\n",
    "ncpus = 1\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809a34e",
   "metadata": {},
   "source": [
    "# Preview input data\n",
    "We can load and preview our input data shapefile using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020710b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((30.71267 30.50485, 30.71085 30.50450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((31.97251 30.45663, 31.97206 30.45661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((31.96894 30.46447, 31.96850 30.46445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((31.92517 30.44214, 31.92481 30.44212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((31.92315 30.45008, 31.92272 30.45006...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                           geometry\n",
       "0      3  POLYGON ((30.71267 30.50485, 30.71085 30.50450...\n",
       "1      3  POLYGON ((31.97251 30.45663, 31.97206 30.45661...\n",
       "2      4  POLYGON ((31.96894 30.46447, 31.96850 30.46445...\n",
       "3      1  POLYGON ((31.92517 30.44214, 31.92481 30.44212...\n",
       "4      0  POLYGON ((31.92315 30.45008, 31.92272 30.45006..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data shapefile\n",
    "input_data = gpd.read_file(path)\n",
    "\n",
    "# Plot first five rows\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f86357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b88d6bd8f24425a8c155796186c7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d738e1c479a54d55bd15151ac4b10b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[30.39767429210498, 31.349509732463098], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training data in an interactive map\n",
    "map_shapefile(input_data, attribute=field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efe125",
   "metadata": {},
   "source": [
    "# Extracting training data\n",
    "The function collect_training_data takes our geojson containing class labels and extracts training data (features) from the datacube over the locations specified by the input geometries. The function will also pre-process our training data by stacking the arrays into a useful format and removing any NaN or inf values.The below variables can be set within the collect_training_data function:\n",
    "\n",
    "* zonal_stats: An optional string giving the names of zonal statistics to calculate across each polygon (if the geometries in the vector file are polygons and not points). Default is None (all pixel values are returned). Supported values are 'mean', 'median', 'max', and 'min'.\n",
    "\n",
    "In addition to the zonal_stats parameter, we also need to set up a datacube query dictionary for the Open Data Cube query such as measurements (the bands to load from the satellite), the resolution (the cell size), and the output_crs (the output projection). These options will be added to a query dictionary that will be passed into collect_training_data using the parameter collect_training_data(dc_query=query, ...). The query dictionary will be the only argument in the feature layer function which we will define and describe in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a2ee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:6933\n"
     ]
    }
   ],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "zonal_stats = 'mean'\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'time': ('2022'),\n",
    "    'resolution': (-20, 20),\n",
    "    'measurements': ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
    "}\n",
    "\n",
    "# Identify the most common projection system in the input query\n",
    "output_crs = mostcommon_crs(dc=dc, product='gm_s2_annual', query=query)\n",
    "print(output_crs)\n",
    "\n",
    "query.update({\"output_crs\": output_crs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a208868",
   "metadata": {},
   "source": [
    "## Defining feature layers\n",
    "To create the desired feature layers, we pass instructions to collect_training_data through the feature_func parameter.\n",
    "\n",
    "feature_func: A function for generating feature layers that is applied to the data within the bounds of the input geometry. The feature_func must accept a dc_query dictionary, and return a single xarray.Dataset or xarray.DataArray containing 2D coordinates (i.e x, y - no time dimension). e.g.\n",
    "\n",
    "    def feature_function(query):\n",
    "        dc = datacube.Datacube(app='feature_layers')\n",
    "        ds = dc.load(**query)\n",
    "        ds = ds.mean('time')\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46615272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_layers(dc, query):\n",
    "    #load s2 annual geomedian\n",
    "    ds = dc.load(product='gm_s2_annual',\n",
    "                 **query)\n",
    "    #calculate some band indices\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI', 'NDCI', 'IRECI', 'MTCI', 'OTCI', 'MCARI'\n",
    "                                       , 'CI_RedEdge', 'CI_GreenEdge', 'TCARI', 'OSAVI', 'TCARI_OSAVI'],\n",
    "                           drop=True,\n",
    "                           satellite_mission='s2')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dfcd0",
   "metadata": {},
   "source": [
    "Run the collect_training_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a747e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking zonal statistic: mean\n",
      "Collecting training data in serial mode\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Dropping bands ['red', 'green', 'red_edge_1', 'red_edge_2', 'red_edge_3', 'nir']\n",
      "Removed 0 rows wth NaNs &/or Infs\n",
      "Output shape:  (58, 12)\n"
     ]
    }
   ],
   "source": [
    "column_names, model_input = collect_training_data(\n",
    "                                    gdf=input_data,\n",
    "                                    dc=dc,\n",
    "                                    dc_query=query,\n",
    "                                    field=field,\n",
    "                                    ncpus = ncpus,\n",
    "                                    zonal_stats=zonal_stats,\n",
    "                                    feature_func=feature_layers\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2953f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'NDVI', 'NDCI', 'IRECI', 'MTCI', 'OTCI', 'MCARI', 'CI_RedEdge', 'CI_GreenEdge', 'TCARI', 'OSAVI', 'TCARI_OSAVI']\n",
      "\n",
      "[[3.   0.68 0.3  0.72 2.74 5.47 0.06 1.75 3.46 0.18 0.58 0.31]\n",
      " [3.   0.51 0.19 0.44 2.39 4.78 0.05 1.03 2.24 0.15 0.44 0.34]\n",
      " [4.   0.51 0.18 0.45 2.61 5.22 0.04 1.15 2.47 0.12 0.44 0.28]\n",
      " [1.   0.33 0.13 0.27 1.55 3.1  0.05 0.51 1.4  0.14 0.3  0.47]\n",
      " [0.   0.25 0.11 0.18 1.1  2.2  0.04 0.3  1.07 0.12 0.21 0.55]\n",
      " [5.   0.36 0.14 0.25 1.71 3.42 0.04 0.59 1.47 0.12 0.31 0.4 ]\n",
      " [5.   0.3  0.11 0.2  1.68 3.35 0.03 0.47 1.29 0.09 0.25 0.35]\n",
      " [2.   0.48 0.21 0.33 1.65 3.3  0.05 0.78 2.16 0.16 0.4  0.41]\n",
      " [3.   0.6  0.27 0.43 2.02 4.03 0.06 1.15 2.8  0.17 0.48 0.35]\n",
      " [5.   0.38 0.15 0.27 1.76 3.51 0.04 0.61 1.6  0.13 0.32 0.4 ]\n",
      " [5.   0.47 0.17 0.39 2.3  4.59 0.05 0.95 2.11 0.14 0.41 0.34]\n",
      " [4.   0.47 0.18 0.41 2.21 4.42 0.05 0.89 2.   0.15 0.41 0.37]\n",
      " [4.   0.49 0.18 0.45 2.43 4.86 0.05 0.98 2.2  0.15 0.43 0.35]\n",
      " [2.   0.49 0.17 0.38 2.42 4.84 0.04 1.01 2.24 0.12 0.41 0.3 ]\n",
      " [0.   0.23 0.09 0.14 1.07 2.15 0.03 0.28 1.07 0.09 0.19 0.45]\n",
      " [0.   0.38 0.15 0.3  1.82 3.63 0.04 0.67 1.66 0.12 0.33 0.39]\n",
      " [5.   0.5  0.23 0.29 1.59 3.18 0.05 0.79 1.99 0.15 0.39 0.39]\n",
      " [4.   0.51 0.23 0.3  1.62 3.25 0.05 0.82 2.03 0.15 0.4  0.38]\n",
      " [3.   0.5  0.23 0.29 1.55 3.1  0.05 0.78 2.01 0.15 0.39 0.39]\n",
      " [2.   0.33 0.14 0.18 1.3  2.61 0.04 0.45 1.35 0.11 0.27 0.42]\n",
      " [1.   0.2  0.1  0.13 0.75 1.5  0.04 0.19 0.86 0.11 0.17 0.61]\n",
      " [3.   0.43 0.16 0.27 1.97 3.94 0.04 0.78 1.97 0.11 0.35 0.3 ]\n",
      " [0.   0.22 0.09 0.15 1.09 2.18 0.03 0.28 1.05 0.09 0.19 0.45]\n",
      " [0.   0.19 0.08 0.14 0.96 1.91 0.03 0.23 0.95 0.08 0.17 0.49]\n",
      " [0.   0.19 0.08 0.14 0.96 1.92 0.03 0.23 0.95 0.08 0.17 0.49]\n",
      " [0.   0.21 0.08 0.15 1.08 2.17 0.03 0.26 1.   0.08 0.18 0.46]\n",
      " [5.   0.52 0.21 0.37 1.94 3.87 0.05 0.96 2.09 0.15 0.42 0.36]\n",
      " [4.   0.47 0.21 0.38 1.65 3.3  0.07 0.74 1.83 0.2  0.4  0.49]\n",
      " [1.   0.35 0.13 0.26 1.82 3.65 0.04 0.58 1.49 0.11 0.31 0.37]\n",
      " [1.   0.29 0.11 0.2  1.6  3.21 0.03 0.44 1.2  0.1  0.25 0.39]\n",
      " [2.   0.36 0.13 0.26 1.87 3.75 0.04 0.6  1.5  0.12 0.31 0.37]\n",
      " [3.   0.67 0.3  0.72 2.7  5.39 0.06 1.7  3.38 0.18 0.58 0.32]\n",
      " [3.   0.6  0.26 0.6  2.53 5.05 0.06 1.45 2.97 0.17 0.51 0.32]\n",
      " [3.   0.62 0.27 0.64 2.67 5.35 0.06 1.52 3.1  0.17 0.53 0.31]\n",
      " [4.   0.53 0.26 0.37 1.44 2.88 0.07 0.8  2.1  0.21 0.43 0.47]\n",
      " [3.   0.44 0.18 0.27 1.67 3.35 0.04 0.72 1.92 0.13 0.36 0.36]\n",
      " [2.   0.7  0.32 0.71 2.79 5.59 0.06 1.88 3.82 0.17 0.59 0.29]\n",
      " [1.   0.34 0.12 0.25 1.9  3.81 0.04 0.58 1.4  0.11 0.3  0.37]\n",
      " [3.   0.3  0.13 0.18 1.18 2.36 0.04 0.39 1.25 0.12 0.25 0.47]\n",
      " [2.   0.25 0.1  0.16 1.21 2.41 0.03 0.32 1.1  0.1  0.21 0.46]\n",
      " [3.   0.72 0.33 0.8  2.99 5.98 0.06 2.08 4.13 0.17 0.61 0.28]\n",
      " [4.   0.56 0.24 0.55 2.43 4.87 0.05 1.3  2.75 0.16 0.48 0.34]\n",
      " [1.   0.41 0.14 0.32 2.12 4.24 0.04 0.74 1.66 0.13 0.35 0.36]\n",
      " [5.   0.26 0.11 0.18 1.17 2.35 0.04 0.33 1.08 0.12 0.23 0.51]\n",
      " [3.   0.51 0.21 0.43 2.12 4.24 0.06 0.94 2.09 0.17 0.43 0.39]\n",
      " [3.   0.54 0.22 0.47 2.23 4.47 0.06 1.04 2.24 0.17 0.46 0.38]\n",
      " [3.   0.29 0.12 0.17 1.19 2.37 0.04 0.37 1.25 0.11 0.24 0.44]\n",
      " [2.   0.68 0.3  0.66 2.7  5.4  0.05 1.74 3.59 0.16 0.56 0.29]\n",
      " [2.   0.71 0.31 0.74 2.93 5.86 0.06 1.94 3.87 0.17 0.59 0.28]\n",
      " [2.   0.68 0.28 0.67 2.91 5.81 0.05 1.79 3.6  0.16 0.57 0.28]\n",
      " [2.   0.7  0.3  0.69 2.84 5.69 0.05 1.85 3.73 0.16 0.58 0.28]\n",
      " [2.   0.69 0.3  0.7  2.88 5.76 0.05 1.84 3.69 0.16 0.58 0.28]\n",
      " [2.   0.71 0.31 0.74 2.93 5.85 0.06 1.94 3.87 0.17 0.59 0.28]\n",
      " [4.   0.38 0.16 0.24 1.39 2.77 0.05 0.53 1.59 0.14 0.31 0.45]\n",
      " [5.   0.48 0.17 0.3  2.33 4.65 0.03 0.96 2.2  0.1  0.38 0.27]\n",
      " [1.   0.2  0.07 0.13 1.45 2.9  0.02 0.25 0.95 0.06 0.16 0.35]\n",
      " [1.   0.2  0.08 0.13 1.05 2.1  0.02 0.24 1.04 0.07 0.17 0.43]\n",
      " [1.   0.18 0.07 0.11 1.13 2.26 0.02 0.21 0.93 0.06 0.15 0.36]]\n"
     ]
    }
   ],
   "source": [
    "print(column_names)\n",
    "print('')\n",
    "print(np.array_str(model_input, precision=2, suppress_small=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb643bb",
   "metadata": {},
   "source": [
    "## Create test and traning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073b5201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (46, 12)\n",
      "Test shape: (12, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing data\n",
    "model_train, model_test = model_selection.train_test_split(model_input, \n",
    "                                                           stratify=model_input[:, 0],\n",
    "                                                           train_size=0.8, \n",
    "                                                           random_state=0)\n",
    "print(\"Train shape:\", model_train.shape)\n",
    "print(\"Test shape:\", model_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9e3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the name and location of the output files\n",
    "output_train_file = \"results/training_data.txt\"\n",
    "#set the name and location of the output file\n",
    "output_test_file = \"results/test_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3568ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all columns\n",
    "model_col_indices = [column_names.index(var_name) for var_name in column_names]\n",
    "#Export files to disk\n",
    "np.savetxt(output_train_file, model_train[:, model_col_indices], header=\" \".join(column_names), fmt=\"%4f\")\n",
    "np.savetxt(output_test_file, model_test[:, model_col_indices], header=\" \".join(column_names), fmt=\"%4f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
